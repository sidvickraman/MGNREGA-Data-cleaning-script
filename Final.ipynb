{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge -> Converting to multiple rows -> Basic cleaning/formatting -> Fuzzy match -> Format specific columns -> Flag invalid data -> Create new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel('Sample details.xlsx')\n",
    "df2 = pd.read_excel('Group_details.xlsx')\n",
    "df3 = pd.read_excel('worksite_details.xlsx')\n",
    "df_jh = pd.read_excel('Jharkand Data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.rename(columns = {'KEY':'PARENT_KEY'})\n",
    "df1['PARENT_KEY'] = df1['PARENT_KEY'].str.replace('uuid:', '')\n",
    "df2['PARENT_KEY'] = df2['PARENT_KEY'].str.replace('uuid:', '')\n",
    "df3['PARENT_KEY'] = df3['PARENT_KEY'].str.replace('uuid:', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df1, df2, on = 'PARENT_KEY')\n",
    "df = pd.merge(df, df3, on = 'PARENT_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------MERGED ALL SHEETS BY PARENT_KEY--------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_variables = df.columns.values.tolist() #list of headers\n",
    "value_variables = ['hourly_mes_deta-nsa_1sthr',\n",
    "       'hourly_mes_deta-idle_time_1sthr',\n",
    "       'hourly_mes_deta-passive_time_1sthr',\n",
    "       'hourly_mes_deta-is_worker_activty_cnd_1hrs',\n",
    "       'hourly_mes_deta-new_activity_involved_1hrs',\n",
    "       'hourly_mes_deta-nsa_2ndhr',\n",
    "       'hourly_mes_deta-idle_time_2ndhr',\n",
    "       'hourly_mes_deta-passive_time_2ndhr',\n",
    "       'hourly_mes_deta-is_worker_activty_cnd_2hrs',\n",
    "       'hourly_mes_deta-new_activity_involved_2hrs',\n",
    "       'hourly_mes_deta-nsa_3rdhr',\n",
    "       'hourly_mes_deta-idle_time_3rdhr',\n",
    "       'hourly_mes_deta-passive_time_3rdhr',\n",
    "       'hourly_mes_deta-is_worker_activty_cnd_3hrs',\n",
    "       'hourly_mes_deta-new_activity_involved_3hrs',\n",
    "       'hourly_mes_deta-nsa_4thhr',\n",
    "       'hourly_mes_deta-idle_time_4thhr',\n",
    "       'hourly_mes_deta-passive_time_4thhr',\n",
    "       'hourly_mes_deta-is_worker_activty_cnd_4hrs',\n",
    "       'hourly_mes_deta-new_activity_involved_4hrs',\n",
    "       'hourly_mes_deta-nsa_5thhr',\n",
    "       'hourly_mes_deta-idle_time_5thhr',\n",
    "       'hourly_mes_deta-passive_time_5thhr',\n",
    "       'hourly_mes_deta-is_worker_activty_cnd_5hrs',\n",
    "       'hourly_mes_deta-new_activity_involved_5hrs',\n",
    "       'hourly_mes_deta-nsa_6thhr',\n",
    "       'hourly_mes_deta-idle_time_6thhr',\n",
    "       'hourly_mes_deta-passive_time_6thhr',\n",
    "       'hourly_mes_deta-is_worker_activty_cnd_6hrs',\n",
    "       'hourly_mes_deta-new_activity_involved_6hrs',\n",
    "       'hourly_mes_deta-nsa_7thhr',\n",
    "       'hourly_mes_deta-idle_time_7thhr',\n",
    "       'hourly_mes_deta-passive_time_7thhr',\n",
    "       'grp_prod_in_1sthr',\n",
    "       'grp_prod_in_2ndhr',\n",
    "       'grp_prod_in_3rdhr',\n",
    "       'grp_prod_in_4thhr',\n",
    "       'grp_prod_in_5thhr',\n",
    "       'grp_prod_in_6thhr',\n",
    "       'grp_prod_in_7thhr'\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "for x in value_variables:\n",
    "    if x in id_variables:\n",
    "        id_variables.remove(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Parent_Key as main index, Use Name as secondary Index, Job card Id as tertiary Index, Use 1-7 for quaternary index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set_index to set name_tms_worker as index\n",
    "#--------------------------------CELL FOR CREATING MULTIPLE ROWS OF DATA--------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbc = ['Total Work time calculated (in mins)',\n",
    "       'Total Work time (in mins)',\n",
    "       'Total day active Time (mins)', \n",
    "       'Total day idleTime (mins)', \n",
    "       'Total day passive Time (mins)',\n",
    "       'total_breakTime (in mins)',\n",
    "       'Bio-Physical classification (Sample)',\n",
    "       'Bio-Physical classification (other than sample in NSA from UoR & TMS)',\n",
    "       'Bio-Physical classification (other than sample in NSA by imputation using  inferential guessing )',\n",
    "       'Lead in meter_1sthr_ind',\n",
    "       'Lift in meter_1sthr_ind',\n",
    "       'Vol in cubic meter_1sthr_ind',\n",
    "       'Depth in meter_1sthr_ind',\n",
    "       'Area in sq.meter_1sthr_ind',\n",
    "       'Length in meter_1sthr_ind',\n",
    "       'Width in meter_1sthr_ind',\n",
    "       'Diameter in meter_1sthr_ind',\n",
    "       'NOS_1sthr_ind',\n",
    "       ' Height of lead (m)',\n",
    "       ' Height of lead (m).1',\n",
    "       ' Slope',\n",
    "       ' Slope.1',\n",
    "       'NSA_avg'\n",
    "       'MORD template Code',\n",
    "       'Lead in meter_1sthr',\n",
    "        'Lift in meter_1sthr',\n",
    "        'Vol in cubic meter_1sthr',\n",
    "        'Depth in meter_1sthr',\n",
    "        'Area in sq.meter_1sthr',\n",
    "        'Length in meter_1sthr',\n",
    "        'Width in meter_1sthr',\n",
    "        'Diameter in meter_1sthr',\n",
    "       'Hour of the working day'\n",
    "      ]  #to be removed columns\n",
    "\n",
    "\n",
    "not_in_sheets = ['NSA_avg',\n",
    "'NSA_f_abled',\n",
    "'NSA_m_abled',\n",
    "'NSA_f_elderly',\n",
    "'NSA_m_elderly',\n",
    "'NSA_disabled',\n",
    "'NSA_debilitated',\n",
    "'MORD template Code',\n",
    "'NOS_1sthr_ind',\n",
    "'Work Site SOIL TYPE',\n",
    "'NOS_1sthr'\n",
    "                ]\n",
    "\n",
    "useless_columns = ['KEY',\n",
    "                    'Group Key',\n",
    "                    'SET-OF-demographic_data',\n",
    "                    'Key Identifier for Group Inf',\n",
    "                  'grp_activity_involved.1']\n",
    "all_columns = df.columns.values.tolist()\n",
    "tbr = tbc+not_in_sheets+useless_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = df_jh.columns.values.tolist() + value_variables #list of headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in tbr:     #remove column headings in headers that need to be calculated seperately\n",
    "    if column in headers:\n",
    "        headers.remove(column) \n",
    "\n",
    "#headers = required columns\n",
    "df = df.drop_duplicates(subset = 'name_tms_worker')\n",
    "\n",
    "for column in all_columns:\n",
    "    if column not in headers:\n",
    "         df.drop(column, inplace=True, axis=1)     #delete unneeded columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------DELETED UNNECCESSARY COLUMNS/ROWS--------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating active time columns from passive and idle time\n",
    "df['hourly_mes_deta-active_time_1sthr'] = 60 - df['hourly_mes_deta-passive_time_1sthr'] - df['hourly_mes_deta-idle_time_1sthr']\n",
    "df['hourly_mes_deta-active_time_2ndhr'] = 60 - df['hourly_mes_deta-passive_time_2ndhr'] - df['hourly_mes_deta-idle_time_2ndhr']\n",
    "df['hourly_mes_deta-active_time_3rdhr'] = 60 - df['hourly_mes_deta-passive_time_3rdhr'] - df['hourly_mes_deta-idle_time_3rdhr']\n",
    "df['hourly_mes_deta-active_time_4thhr'] = 60 - df['hourly_mes_deta-passive_time_4thhr'] - df['hourly_mes_deta-idle_time_4thhr']\n",
    "df['hourly_mes_deta-active_time_5thhr'] = 60 - df['hourly_mes_deta-passive_time_5thhr'] - df['hourly_mes_deta-idle_time_5thhr']\n",
    "df['hourly_mes_deta-active_time_6thhr'] = 60 - df['hourly_mes_deta-passive_time_6thhr'] - df['hourly_mes_deta-idle_time_6thhr']\n",
    "df['hourly_mes_deta-active_time_7thhr'] = 60 - df['hourly_mes_deta-passive_time_7thhr'] - df['hourly_mes_deta-idle_time_7thhr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['grp_prod_in_1sthr'] = df['grp_prod_in_1sthr'].str.replace('\\n', '')\n",
    "df['grp_prod_in_2ndhr'] = df['grp_prod_in_2ndhr'].str.replace('\\n', '')\n",
    "df['grp_prod_in_3rdhr'] = df['grp_prod_in_3rdhr'].str.replace('\\n', '')\n",
    "df['grp_prod_in_4thhr'] = df['grp_prod_in_4thhr'].str.replace('\\n', '')\n",
    "df['grp_prod_in_5thhr'] = df['grp_prod_in_5thhr'].str.replace('\\n', '')\n",
    "df['grp_prod_in_6thhr'] = df['grp_prod_in_6thhr'].str.replace('\\n', '')\n",
    "df['grp_prod_in_7thhr'] = df['grp_prod_in_7thhr'].str.replace('\\n', '')\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "df['grp_prod_in_1sthr'] = df['grp_prod_in_1sthr'].str.replace(r' ', '', regex=True)\n",
    "\n",
    "df['Lead'] = df['grp_prod_in_1sthr'].str.extract(r'(?i)Lead\\W(\\d+)')\n",
    "df['Lift'] = df['grp_prod_in_1sthr'].str.extract(r'(?i)Lift\\W(\\d+)')\n",
    "df['Volume'] = df['grp_prod_in_1sthr'].str.extract(r'(?i)Vol\\W(\\d+)')\n",
    "df['Depth'] = df['grp_prod_in_1sthr'].str.extract(r'(?i)Depth\\W(\\d+)')\n",
    "df['Length'] = df['grp_prod_in_1sthr'].str.extract(r'(?i)Length\\W(\\d+)')\n",
    "df['Breadth'] = df['grp_prod_in_1sthr'].str.extract(r'(?i)Breadth\\W(\\d+)')\n",
    "df['Diameter'] = df['grp_prod_in_1sthr'].str.extract(r'(?i)Diameter\\W(\\d+)')\n",
    "df['Nos'] = df['grp_prod_in_1sthr'].str.extract(r'(?i)Nos\\W(\\d+)')\n",
    "df['HeightofLead'] = df['grp_prod_in_1sthr'].str.extract(r'(?i)HeightofLead\\W(\\d+)')\n",
    "df['Slope'] = df['grp_prod_in_1sthr'].str.extract(r'(?i)Slope\\W(\\d+)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Total Idle Time'] = df['hourly_mes_deta-idle_time_1sthr'] + df['hourly_mes_deta-idle_time_2ndhr'] + df['hourly_mes_deta-idle_time_3rdhr'] + df['hourly_mes_deta-idle_time_4thhr'] + df['hourly_mes_deta-idle_time_5thhr'] + df['hourly_mes_deta-idle_time_6thhr'] + df['hourly_mes_deta-idle_time_7thhr']\n",
    "df['Total Passive Time'] = df['hourly_mes_deta-passive_time_1sthr'] + df['hourly_mes_deta-passive_time_2ndhr'] + df['hourly_mes_deta-passive_time_3rdhr'] + df['hourly_mes_deta-passive_time_4thhr'] + df['hourly_mes_deta-passive_time_5thhr'] + df['hourly_mes_deta-passive_time_6thhr'] + df['hourly_mes_deta-passive_time_7thhr']\n",
    "df['Total Active Time'] = df['hourly_mes_deta-active_time_1sthr'] + df['hourly_mes_deta-active_time_2ndhr'] + df['hourly_mes_deta-active_time_3rdhr'] + df['hourly_mes_deta-active_time_4thhr'] + df['hourly_mes_deta-active_time_5thhr'] + df['hourly_mes_deta-active_time_6thhr'] + df['hourly_mes_deta-active_time_7thhr']\n",
    "df['Total Work Time'] = df['Total Idle Time'] + df['Total Passive Time'] + df['Total Active Time']\n",
    "#df['Individual Volume Output'] = df['Total Active Time']/df['Active Time first worker']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Group Total Active Time'] = df.groupby('PARENT_KEY')['Total Active Time'].transform('sum')\n",
    "df['Individual Output'] = df['Total Active Time']/df['Group Total Active Time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------CREATED PASSIVE, ACTIVE, IDLE, AND WORK TIME COLUMNS --------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['name_tms_worker'] = df['name_tms_worker'].str.replace('\\d+', '')   #formatting name column to remove numbers\n",
    "df['mgnregs_job_card_number'] = df['mgnregs_job_card_number'].str.replace('No :', '')  #removing no :\n",
    "df = df.replace(to_replace='^[a-z][_]', value='', regex=True)\n",
    "df['nature_of_debilitating_health'] = df['nature_of_debilitating_health'].str.replace('deb_', '')\n",
    "df['is_differently_abled'] = df['is_differently_abled'].str.replace('da_', '')\n",
    "df['nature_of_different_ability'] = df['nature_of_different_ability'].str.replace('diff_', '')\n",
    "df['worksite_details-worksite_id'] = df['worksite_details-worksite_id'].str.replace('ID :', '')\n",
    "df['data_workers_wages_facilities-work_site_facilities'] = df['data_workers_wages_facilities-work_site_facilities'].str.replace(' fac_', ', ')\n",
    "df['data_workers_wages_facilities-work_site_facilities'] = df['data_workers_wages_facilities-work_site_facilities'].str.replace('fac_', '')\n",
    "df['sample_grp_inf-is_worker_in_group'] = df['sample_grp_inf-is_worker_in_group'].str.replace('grp_', '')\n",
    "df = df.replace(to_replace='[_]', value=' ', regex=True)\n",
    "df['sample_grp_inf-is_worker_in_group'] = df['sample_grp_inf-is_worker_in_group'].str.replace('tool ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------BASIC GRAMMAR FORMATTING --------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_variables = list(df.columns.values)   #creating lists of column names that need to be stacked\n",
    "\n",
    "active_cols = ['hourly_mes_deta-active_time_1sthr', 'hourly_mes_deta-active_time_2ndhr', 'hourly_mes_deta-active_time_3rdhr', 'hourly_mes_deta-active_time_4thhr', 'hourly_mes_deta-active_time_5thhr', 'hourly_mes_deta-active_time_6thhr', 'hourly_mes_deta-active_time_7thhr']\n",
    "activity_cols = ['hourly_mes_deta-new_activity_involved_1hrs', 'hourly_mes_deta-new_activity_involved_2hrs', 'hourly_mes_deta-new_activity_involved_3hrs', 'hourly_mes_deta-new_activity_involved_4hrs', 'hourly_mes_deta-new_activity_involved_5hrs', 'hourly_mes_deta-new_activity_involved_6hrs', 'hourly_mes_deta-new_activity_involved_7hrs']\n",
    "idle_cols = ['hourly_mes_deta-idle_time_1sthr', 'hourly_mes_deta-idle_time_2ndhr', 'hourly_mes_deta-idle_time_3rdhr', 'hourly_mes_deta-idle_time_4thhr', 'hourly_mes_deta-idle_time_5thhr', 'hourly_mes_deta-idle_time_6thhr', 'hourly_mes_deta-idle_time_7thhr']\n",
    "passive_cols = ['hourly_mes_deta-passive_time_1sthr', 'hourly_mes_deta-passive_time_2ndhr', 'hourly_mes_deta-passive_time_3rdhr', 'hourly_mes_deta-passive_time_4thhr', 'hourly_mes_deta-passive_time_5thhr', 'hourly_mes_deta-passive_time_6thhr', 'hourly_mes_deta-passive_time_7thhr']\n",
    "worker_cols = ['hourly_mes_deta-is_worker_activty_cnd_1hrs', 'hourly_mes_deta-is_worker_activty_cnd_2hrs', 'hourly_mes_deta-is_worker_activty_cnd_3hrs', 'hourly_mes_deta-is_worker_activty_cnd_4hrs', 'hourly_mes_deta-is_worker_activty_cnd_5hrs', 'hourly_mes_deta-is_worker_activty_cnd_6hrs', 'hourly_mes_deta-is_worker_activty_cnd_7hrs']\n",
    "nsa_cols = ['hourly_mes_deta-nsa_1sthr', 'hourly_mes_deta-nsa_2ndhr', 'hourly_mes_deta-nsa_3rdhr', 'hourly_mes_deta-nsa_4thhr', 'hourly_mes_deta-nsa_5thhr', 'hourly_mes_deta-nsa_6thhr', 'hourly_mes_deta-nsa_7thhr']\n",
    "\n",
    "all_cols = [active_cols, activity_cols, idle_cols, passive_cols, worker_cols, nsa_cols]\n",
    "\n",
    "for cols in all_cols:\n",
    "    for col in cols:\n",
    "        if col not in headers:\n",
    "            cols.remove(col)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in idle_cols:\n",
    "    if col in id_variables:\n",
    "        id_variables.remove(col)\n",
    "\n",
    "df = df.melt(id_vars = id_variables, value_vars = idle_cols, var_name = 'Hour Number', value_name = \"Idle Time\").sort_values(by = ['name_tms_worker', 'Hour Number']).dropna()\n",
    "df['Hour Number'] = df['Hour Number'].str.extract(r'(\\d+)')\n",
    "\n",
    "id_variables.append('Hour Number')\n",
    "id_variables.append('Idle Time')\n",
    "\n",
    "for col in passive_cols:\n",
    "    if col in id_variables:\n",
    "        id_variables.remove(col)\n",
    "\n",
    "df = df.melt(id_vars = id_variables, value_vars = passive_cols, var_name = 'variable', value_name = 'Passive Time')\n",
    "df['variable'] = df['variable'].str.extract(r'(\\d+)')\n",
    "df = df[df['variable'] == df['Hour Number']].sort_values(by=['name_tms_worker', 'Hour Number'])\n",
    "df = df.drop(labels = 'variable', axis = 1)\n",
    "id_variables.append('Passive Time')\n",
    "\n",
    "for col in active_cols:\n",
    "    if col in id_variables:\n",
    "        id_variables.remove(col)\n",
    "\n",
    "df = df.melt(id_vars = id_variables, value_vars = active_cols, var_name = 'variable', value_name = 'Active Time')\n",
    "df['variable'] = df['variable'].str.extract(r'(\\d+)')\n",
    "df = df[df['variable'] == df['Hour Number']].sort_values(by=['name_tms_worker', 'Hour Number'])\n",
    "df = df.drop(labels = 'variable', axis = 1)\n",
    "id_variables.append('Active Time')\n",
    "\n",
    "\n",
    "for col in worker_cols:\n",
    "    if col in id_variables:\n",
    "        id_variables.remove(col)\n",
    "\n",
    "df = df.melt(id_vars = id_variables, value_vars = worker_cols, var_name = 'variable', value_name = 'Is worker hours cnd')\n",
    "df['variable'] = df['variable'].str.extract(r'(\\d+)')\n",
    "df = df[df['variable'] == df['Hour Number']].sort_values(by=['name_tms_worker', 'Hour Number'])\n",
    "df = df.drop(labels = 'variable', axis = 1)\n",
    "id_variables.append('Is worker hours cnd')\n",
    "\n",
    "for col in nsa_cols:\n",
    "    if col in id_variables:\n",
    "        id_variables.remove(col)\n",
    "\n",
    "df = df.melt(id_vars = id_variables, value_vars = nsa_cols, var_name = 'variable', value_name = 'NSA')\n",
    "df['variable'] = df['variable'].str.extract(r'(\\d+)')\n",
    "df = df[df['variable'] == df['Hour Number']].sort_values(by=['name_tms_worker', 'Hour Number'])\n",
    "df = df.drop(labels = 'variable', axis = 1)\n",
    "id_variables.append('NSA')\n",
    "\n",
    "for col in activity_cols:\n",
    "    if col in id_variables:\n",
    "        id_variables.remove(col)\n",
    "\n",
    "df = df.melt(id_vars = id_variables, value_vars = activity_cols, var_name = 'variable', value_name = 'New activity involved')\n",
    "df['variable'] = df['variable'].str.extract(r'(\\d+)')\n",
    "df = df[df['variable'] == df['Hour Number']].sort_values(by=['name_tms_worker', 'Hour Number'])\n",
    "df = df.drop(labels = 'variable', axis = 1)\n",
    "id_variables.append('New activity involved')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------STACKED COLUMNS BASED ON HOUR NUMBER--------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('Final.xlsx', engine='xlsxwriter')\n",
    "df.to_excel(writer)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
